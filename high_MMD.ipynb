{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-dimensional MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gamma\n",
    "import pickle\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import pairwise_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "dim = 10\n",
    " \n",
    "# how many samples\n",
    "sample_size = 256\n",
    "sample_points = np.linspace(0, 1, dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating high-dimensional distributions \n",
    "\n",
    "## Generating process for mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating distributions over time for mean shift\n",
    "\n",
    "def gen_mean_shift(sample_size, sample_points, delta=0, sd=np.sqrt(0.25), random_state=None):\n",
    "    \"\"\"    \n",
    "    sample_size : number of function samples\n",
    "    sample_points : observation points\n",
    "    delta : the coefficient of X^3\n",
    "    sd : the standard deviation of the observation noise\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    n_points = len(sample_points)\n",
    "    X = rng.normal(0, np.sqrt(10), (sample_size,1)) * np.sqrt(2) * np.sin(2*np.pi*sample_points) + rng.normal(0, np.sqrt(5), (sample_size,1)) * np.sqrt(2) * np.cos(2*np.pi*sample_points)    # Fourier basis functions\n",
    "    X += sample_points + delta * sample_points**3    # adding mean function\n",
    "    X += rng.normal(0, sd, (sample_size,n_points))    # adding noise epsilon\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating process for variance shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating distributions over time for variance shift\n",
    "\n",
    "def gen_variance_shift(sample_size, sample_points, delta=0, sd=np.sqrt(0.25), random_state=None):\n",
    "    \"\"\"    \n",
    "    sample_size : number of function samples\n",
    "    sample_points : observation points\n",
    "    delta : controls the variance of the sin term.\n",
    "    sd : the standard deviation of the observation noise\n",
    "    \"\"\"\n",
    "    rng = np.random.RandomState(random_state)\n",
    "    n_points = len(sample_points)\n",
    "    X = rng.normal(0, np.sqrt(10+delta), (sample_size,1)) * np.sqrt(2) * np.sin(2*np.pi*sample_points) + rng.normal(0, np.sqrt(5), (sample_size,1)) * np.sqrt(2) * np.cos(2*np.pi*sample_points)\n",
    "    X += rng.normal(0, sd, (sample_size,n_points))    # adding noise epsilon\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median heuristic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median heuristic for kernel width\n",
    "def width(Z):\n",
    "    dist_mat = pairwise_distances(Z, metric='euclidean')\n",
    "    width_Z = np.median(dist_mat[dist_mat > 0])\n",
    "    \n",
    "    return width_Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "# Statistical test based on MMD\n",
    "We test statistically whether $\\mathcal{H}_0 : P_X = P_Y$ holds true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMD with permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_permutations(X, Y, alpha, width_XY, shuffle): # set widths to -1 for median heuristics\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    n = Y.shape[0]\n",
    "    \n",
    "    # median heuristics for kernel width\n",
    "    if width_XY == -1:\n",
    "        width_XY = width(np.concatenate([X, Y]))   # aggregating samples\n",
    "    \n",
    "    # compute Gram matrices\n",
    "    K = pairwise_kernels(X, X, metric='rbf', gamma=0.5/(width_XY**2))\n",
    "    L = pairwise_kernels(Y, Y, metric='rbf', gamma=0.5/(width_XY**2))\n",
    "    KL = pairwise_kernels(X, Y, metric='rbf', gamma=0.5/(width_XY**2))\n",
    "    \n",
    "    K_diag = K - np.diag(np.diagonal(K))\n",
    "    L_diag = L - np.diag(np.diagonal(L))\n",
    "    \n",
    "    # biased test statistic\n",
    "    #stat = 1/m * (np.sum(K + L - KL - KL.T))\n",
    "    \n",
    "    # unbiased test statistic\n",
    "    stat = (1/(m*(m-1)))*np.sum(K-K_diag) + (1/(n*(n-1)))*np.sum(L-L_diag) - (2/(m*n))*np.sum(KL)\n",
    "    \n",
    "    Kz = np.concatenate((np.concatenate((K, KL), axis=1), np.concatenate((KL.T, L), axis=1)), axis=0)\n",
    "    \n",
    "    # initiating MMD\n",
    "    MMD_arr = np.zeros(shuffle)\n",
    "    \n",
    "    # create permutations by reshuffling L except the main diagonal\n",
    "    for sh in range(shuffle):\n",
    "        index_perm = np.random.permutation(Kz.shape[0])\n",
    "        Kz_perm = Kz[index_perm, index_perm[:, None]]\n",
    "        \n",
    "        K = Kz_perm[:m, :m]\n",
    "        L = Kz_perm[m:, m:]\n",
    "        KL = Kz_perm[:m, m:]\n",
    "        \n",
    "        K_diag = K - np.diag(np.diagonal(K))\n",
    "        L_diag = L - np.diag(np.diagonal(L))\n",
    "        \n",
    "        # biased\n",
    "        #MMD_arr[sh] = 1/m * (np.sum(K + L - KL - KL.T))\n",
    "        \n",
    "        # unbiased\n",
    "        MMD_arr[sh] = (1/(m*(m-1)))*np.sum(K-K_diag) + (1/(n*(n-1)))*np.sum(L-L_diag) - (2/(m*n))*np.sum(KL)\n",
    "        \n",
    "    MMD_arr_sort = np.sort(MMD_arr)\n",
    "    \n",
    "    # computing 1-alpha threshold\n",
    "    threshold = MMD_arr_sort[round((1-alpha)*shuffle)]\n",
    "        \n",
    "    \"\"\"\n",
    "    if stat > threshold:\n",
    "        print('H0 rejected')\n",
    "    else:\n",
    "        print('H0 accepted')\n",
    "    \"\"\"\n",
    "    \n",
    "    return stat, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MMD with Gamma distribution approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MMD_gamma(X, Y, alpha, width_XY):    # set widths to -1 for median heuristics\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    n = Y.shape[0]\n",
    "    \n",
    "    # median heuristics for kernel width\n",
    "    if width_XY == -1:\n",
    "        width_XY = width(np.concatenate([X, Y]))   # aggregating samples\n",
    "    \n",
    "    # compute Gram matrices\n",
    "    K = pairwise_kernels(X, X, metric='rbf', gamma=0.5/(width_XY**2))\n",
    "    L = pairwise_kernels(Y, Y, metric='rbf', gamma=0.5/(width_XY**2))\n",
    "    KL = pairwise_kernels(X, Y, metric='rbf', gamma=0.5/(width_XY**2))\n",
    "    \n",
    "    K_diag = K - np.diag(np.diagonal(K))\n",
    "    L_diag = L - np.diag(np.diagonal(L))\n",
    "    KL_diag = KL - np.diag(np.diagonal(KL))\n",
    "    \n",
    "    # biased test statistic\n",
    "    #stat = 1/m * (np.sum(K + L - KL - KL.T))\n",
    "    \n",
    "    # unbiased test statistic\n",
    "    stat = (1/(m*(m-1)))*np.sum(K-K_diag) + (1/(n*(n-1)))*np.sum(L-L_diag) - (2/(m*n))*np.sum(KL)\n",
    "    \n",
    "    # fitting Gamma distribution to stat\n",
    "    mMMD = 2/m * (1 - 1/m * np.trace(KL))    # mean under H0\n",
    "    \n",
    "    varMMD = 2/(m*(m-1)) * 1/(m*(m-1)) * np.sum(np.power((K_diag + L_diag - KL_diag - KL_diag.T), 2))    # variance under H0\n",
    "    \n",
    "    al = mMMD**2 / varMMD\n",
    "    bet = varMMD * m / mMMD\n",
    "    \n",
    "    # computing 1-alpha threshold\n",
    "    threshold = gamma.ppf(1-alpha, al, scale=bet)\n",
    "    \n",
    "    \"\"\"\n",
    "    if stat > threshold:\n",
    "        print('H0 rejected')\n",
    "    else:\n",
    "        print('H0 accepted')\n",
    "    \"\"\"\n",
    "    \n",
    "    return stat, threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power estimation\n",
    "\n",
    "We estimate the statistical power based on 200 replications for each setting. Our experiment settings compose of various dimensions, sample sizes, mean shifts `delta_m`, and variance shifts `delta_var`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "dims = [5, 10, 25, 50, 100]\n",
    "\n",
    "# sample sizes\n",
    "sample_sizes = [100, 200, 300, 500]\n",
    "\n",
    "# mean and variance shifts\n",
    "delta_m = np.linspace(0, 8, 17)\n",
    "delta_var = np.linspace(0, 32, 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power estimation for mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMD_p_m = {}\n",
    "MMD_g_m = {}\n",
    "\n",
    "for dim in dims:\n",
    "    print('Dimensions:', dim)\n",
    "    sample_points = np.linspace(0, 1, dim)\n",
    "    \n",
    "    for sample_size in sample_sizes:\n",
    "        print('Sample size:', sample_size)\n",
    "        for delta in delta_m:\n",
    "            print('delta:', delta)\n",
    "                \n",
    "            MMD_p_m_list = []\n",
    "            MMD_g_m_list = []\n",
    "\n",
    "            # repeating 200 times\n",
    "            for i in range(200):\n",
    "\n",
    "                # defining X\n",
    "                X = gen_mean_shift(sample_size, sample_points, delta=0)    # delta=0 for X\n",
    "\n",
    "                # defining Y\n",
    "                Y = gen_mean_shift(sample_size, sample_points, delta=delta)    # delta=delta for Y\n",
    "\n",
    "                # test level alpha = 0.05, 5000 permutations\n",
    "                MMD_p_m_list.append(MMD_permutations(X, Y, 0.05, -1, 5000))\n",
    "\n",
    "                # test level alpha = 0.05\n",
    "                MMD_g_m_list.append(MMD_gamma(X, Y, 0.05, -1))\n",
    "\n",
    "            MMD_p_m[(dim, sample_size, delta)] = MMD_p_m_list\n",
    "            MMD_g_m[(dim, sample_size, delta)] = MMD_g_m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "m_shift_p = open('mean_shifts_p_{}.pkl'.format(dims), 'wb')\n",
    "pickle.dump(MMD_p_m, m_shift_p)\n",
    "m_shift_p.close()\n",
    "\n",
    "m_shift_g = open('mean_shifts_g_{}.pkl'.format(dims), 'wb')\n",
    "pickle.dump(MMD_g_m, m_shift_g)\n",
    "m_shift_g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power estimation for variance shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMD_p_var = {}\n",
    "MMD_g_var = {}\n",
    "\n",
    "for dim in dims:\n",
    "    print('Dimensions:', dim)\n",
    "    sample_points = np.linspace(0, 1, dim)\n",
    "    \n",
    "    for sample_size in sample_sizes:\n",
    "        print('Sample size:', sample_size)\n",
    "        for delta in delta_var:\n",
    "            print('delta:', delta)\n",
    "                \n",
    "            MMD_p_var_list = []\n",
    "            MMD_g_var_list = []\n",
    "\n",
    "            # repeating 200 times\n",
    "            for i in range(200):\n",
    "\n",
    "                # defining X\n",
    "                X = gen_variance_shift(sample_size, sample_points, delta=0)    # delta=0 for X\n",
    "\n",
    "                # defining Y\n",
    "                Y = gen_variance_shift(sample_size, sample_points, delta=delta)    # delta=delta for Y\n",
    "\n",
    "                # test level alpha = 0.05, 5000 permutations\n",
    "                MMD_p_var_list.append(MMD_permutations(X, Y, 0.05, -1, 5000))\n",
    "\n",
    "                # test level alpha = 0.05\n",
    "                MMD_g_var_list.append(MMD_gamma(X, Y, 0.05, -1))\n",
    "\n",
    "            MMD_p_var[(dim, sample_size, delta)] = MMD_p_var_list\n",
    "            MMD_g_var[(dim, sample_size, delta)] = MMD_g_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "var_shift_p = open('var_shifts_p_{}.pkl'.format(dims), 'wb')\n",
    "pickle.dump(MMD_p_var, var_shift_p)\n",
    "m_shift_p.close()\n",
    "\n",
    "var_shift_g = open('var_shifts_g_{}.pkl'.format(dims), 'wb')\n",
    "pickle.dump(MMD_g_var, var_shift_g)\n",
    "var_shift_g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximising test power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def var_MMD(X, Y):\n",
    "    m = X.shape[0]\n",
    "    K = pairwise_kernels(X, X, metric='rbf', gamma=0.5/(1**2))\n",
    "    L = pairwise_kernels(Y, Y, metric='rbf', gamma=0.5/(1**2))\n",
    "    KL = pairwise_kernels(X, Y, metric='rbf', gamma=0.5/(1**2))\n",
    "    K_diag = np.diag(K)\n",
    "    L_diag = np.diag(L) \n",
    "    \n",
    "    K_sums = np.sum(K, 1) - K_diag\n",
    "    L_sums = np.sum(L, 1) - L_diag\n",
    "\n",
    "    K_sum = np.sum(K_sums)\n",
    "    L_sum = np.sum(L_sums)\n",
    "\n",
    "    KL_sums_0 = np.sum(KL, 0)\n",
    "    KL_sums_1 = np.sum(KL, 1)\n",
    "\n",
    "    KL_sum = np.sum(KL_sums_0)\n",
    "\n",
    "    K_diag_sum = np.sum(K_diag)\n",
    "    L_diag_sum = np.sum(L_diag)\n",
    "\n",
    "    K_diag_sum2 = np.sum(np.power(K_diag, 2))\n",
    "    L_diag_sum2 = np.sum(np.power(L_diag, 2))\n",
    "\n",
    "    K_sqsum = np.sum(np.power(K_sums, 2))\n",
    "    L_sqsum = np.sum(np.power(L_sums, 2))\n",
    "    KL_sqsum_0 = np.sum(np.power(KL_sums_0, 2))\n",
    "    KL_sqsum_1 = np.sum(np.power(KL_sums_1, 2))\n",
    "\n",
    "    K_2_sqsum = np.sum(np.power(K, 2)) - K_diag_sum2\n",
    "    L_2_sqsum = np.sum(np.power(L, 2)) - L_diag_sum2\n",
    "    KL_2_sqsum = np.sum(np.power(KL, 2))\n",
    "    \n",
    "    var_MMD = 2 / (m**2 * (m-1)**2) * (2*K_sqsum - K_2_sqsum + 2*L_sqsum - L_2_sqsum) - (4*m-6) / (m**3 * (m-1)**3) * (K_sum**2 + L_sum**2) + 4*(m-2) / (m**3 * (m-1)**2) * (KL_sqsum_1 + KL_sqsum_0) - 4 * (m-3) / (m**3 * (m-1)**2) * KL_2_sqsum - (8*m - 12) / (m**5 * (m-1)) * KL_sum**2 + 8 / (m**3 * (m-1)) * (1/m * (K_sum + L_sum) * KL_sum - np.dot(K_sums, KL_sums_1) - np.dot(L_sums, KL_sums_0))\n",
    "    \n",
    "    return var_MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximise(MMD, MMD_var, threshold, m):\n",
    "    ratio = MMD / np.sqrt(MMD_var) - threshold / (m*np.sqrt(MMD_var))\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power estimation\n",
    "\n",
    "We estimate the statistical power based on 200 replications for each setting. Our experiment settings compose of various dimensions, sample sizes, mean shifts `delta_m`, and variance shifts `delta_var`. We iterate over pre-defined search spaces for the optimal Gaussian kernel bandwidth $\\sigma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions\n",
    "dims = [5, 10, 25, 50, 100]\n",
    "\n",
    "# sample sizes\n",
    "sample_sizes = [100, 200, 300, 500]\n",
    "\n",
    "# mean and variance shifts\n",
    "delta_m = np.linspace(0, 8, 17)\n",
    "delta_var = np.linspace(0, 32, 33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power estimation for mean shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MMD_p_m = {}\n",
    "MMD_g_m = {}\n",
    "\n",
    "for dim in dims:\n",
    "    print('dimensions:', dim)\n",
    "    sample_points = np.linspace(0, 1, dim)\n",
    "    \n",
    "    for sample_size in sample_sizes:\n",
    "        print('sample size:', sample_size)\n",
    "        for delta in delta_m:\n",
    "            print('delta:', delta)\n",
    "                \n",
    "            MMD_p_m_list = []\n",
    "            MMD_g_m_list = []\n",
    "            \n",
    "            # repeating 200 times\n",
    "            for i in range(200):\n",
    "        \n",
    "                # defining X\n",
    "                X_train = gen_mean_shift(sample_size, sample_points, delta=0)    # delta=0 for X\n",
    "                X_test = gen_mean_shift(sample_size, sample_points, delta=0) \n",
    "\n",
    "                # defining Y\n",
    "                Y_train = gen_mean_shift(sample_size, sample_points, delta=delta)    # delta=delta for Y\n",
    "                Y_test = gen_mean_shift(sample_size, sample_points, delta=delta)\n",
    "\n",
    "                m = X_train.shape[0]\n",
    "\n",
    "                # sigma is dependent on delta\n",
    "                if 0 <= delta <= 2:\n",
    "                    sigmas = np.linspace(1, 21, 11)\n",
    "                elif 2 < delta <= 3:\n",
    "                    sigmas = np.linspace(6, 26, 11)\n",
    "                elif 3 < delta <= 5:\n",
    "                    sigmas = np.linspace(11, 31, 11)\n",
    "                elif 5 < delta <= 8:\n",
    "                    sigmas = np.linspace(16, 36, 11)\n",
    "\n",
    "                ratios = []\n",
    "\n",
    "                for sigma in sigmas:\n",
    "                    MMD, threshold = MMD_permutations(X_train, Y_train, 0.05, sigma, 5000)\n",
    "                    MMD_var = var_MMD(X_train, Y_train)\n",
    "                    ratios.append(maximise(MMD, MMD_var, threshold, m))\n",
    "\n",
    "                # sigma of maximum ratio\n",
    "                sigma_max = sigmas[np.argmax(ratios)]\n",
    "\n",
    "                # test level alpha = 0.05, 5000 permutations\n",
    "                MMD_p_m_list.append(MMD_permutations(X_test, Y_test, 0.05, sigma_max, 5000))\n",
    "\n",
    "                # test level alpha = 0.05\n",
    "                MMD_g_m_list.append(MMD_gamma(X_test, Y_test, 0.05, sigma_max))\n",
    "            \n",
    "            MMD_p_m[(dim, sample_size, delta)] = MMD_p_m_list\n",
    "            MMD_g_m[(dim, sample_size, delta)] = MMD_g_m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "m_shift_p = open('mean_shifts_p_{}_max.pkl'.format(dims), 'wb')\n",
    "pickle.dump(MMD_p_m, m_shift_p)\n",
    "m_shift_p.close()\n",
    "\n",
    "m_shift_g = open('mean_shifts_g_{}_max.pkl'.format(dims), 'wb')\n",
    "pickle.dump(MMD_g_m, m_shift_g)\n",
    "m_shift_g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power estimation for variance shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MMD_p_m = {}\n",
    "MMD_g_m = {}\n",
    "\n",
    "for dim in dims:\n",
    "    print('dimensions:', dim)\n",
    "    sample_points = np.linspace(0, 1, dim)\n",
    "    \n",
    "    for sample_size in sample_sizes:\n",
    "        print('sample size:', sample_size)\n",
    "        for delta in delta_var:\n",
    "            print('delta:', delta)\n",
    "                \n",
    "            MMD_p_m_list = []\n",
    "            MMD_g_m_list = []\n",
    "            \n",
    "            # repeating 200 times\n",
    "            for i in range(200):\n",
    "        \n",
    "                # defining X\n",
    "                X_train = gen_variance_shift(sample_size, sample_points, delta=0)    # delta=0 for X\n",
    "                X_test = gen_variance_shift(sample_size, sample_points, delta=0) \n",
    "\n",
    "                # defining Y\n",
    "                Y_train = gen_variance_shift(sample_size, sample_points, delta=delta)    # delta=delta for Y\n",
    "                Y_test = gen_variance_shift(sample_size, sample_points, delta=delta)\n",
    "\n",
    "                m = X_train.shape[0]\n",
    "\n",
    "                # sigma is dependent on delta\n",
    "                if 0 <= delta <= 4:\n",
    "                    sigmas = np.linspace(10, 30, 11)\n",
    "                elif 4 < delta <= 14:\n",
    "                    sigmas = np.linspace(20, 40, 11)\n",
    "                elif 14 < delta <= 32:\n",
    "                    sigmas = np.linspace(30, 50, 11)\n",
    "\n",
    "                ratios = []\n",
    "\n",
    "                for sigma in sigmas:\n",
    "                    MMD, threshold = MMD_permutations(X_train, Y_train, 0.05, sigma, 5000)\n",
    "                    MMD_var = var_MMD(X_train, Y_train)\n",
    "                    ratios.append(maximise(MMD, MMD_var, threshold, m))\n",
    "\n",
    "                # sigma of maximum ratio\n",
    "                sigma_max = sigmas[np.argmax(ratios)]\n",
    "\n",
    "                # test level alpha = 0.05, 5000 permutations\n",
    "                MMD_p_m_list.append(MMD_permutations(X_test, Y_test, 0.05, sigma_max, 5000))\n",
    "\n",
    "                # test level alpha = 0.05\n",
    "                MMD_g_m_list.append(MMD_gamma(X_test, Y_test, 0.05, sigma_max))\n",
    "            \n",
    "            MMD_p_m[(dim, sample_size, delta)] = MMD_p_m_list\n",
    "            MMD_g_m[(dim, sample_size, delta)] = MMD_g_m_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving\n",
    "var_shift_p = open('var_shifts_p_{}_max.pkl'.format(dims), 'wb')\n",
    "pickle.dump(MMD_p_var, var_shift_p)\n",
    "m_shift_p.close()\n",
    "\n",
    "var_shift_g = open('var_shifts_g_{}_max.pkl'.format(dims), 'wb')\n",
    "pickle.dump(MMD_g_var, var_shift_g)\n",
    "var_shift_g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
